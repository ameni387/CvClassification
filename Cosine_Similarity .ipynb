{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d220a6",
   "metadata": {},
   "source": [
    "# Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ce64f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\r i b\\anaconda3\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (71.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aec5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\r i b\\anaconda3\\lib\\site-packages (5.22.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\r i b\\anaconda3\\lib\\site-packages (from neo4j) (2022.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86a1b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\r i b\\anaconda3\\lib\\site-packages (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6537f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import docx2txt\n",
    "def clean_text_from_file(file_path):\n",
    "    try:\n",
    "        # Extract text from .docx file\n",
    "        text = docx2txt.process(file_path)\n",
    "        # Define characters to remove \n",
    "        unnecessary_chars = re.compile(r'[^a-zA-Z0-9\\s.,;:’èé+#Éàâ()ôÔ&/-]')\n",
    "        # Remove unnecessary characters\n",
    "        cleaned_text = unnecessary_chars.sub('', text)\n",
    "        # Remove extra spaces and join into one paragraph\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "        return cleaned_text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An error occurred while processing the file '{file_path}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e89e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(list1, list2):\n",
    "    # Convert all skills to lowercase\n",
    "    list1 = list(map(str.lower, list1))\n",
    "    list2 = list(map(str.lower, list2))\n",
    "    \n",
    "    # Create a combined list of unique skills\n",
    "    skills = list(set(list1).union(set(list2)))\n",
    "    \n",
    "    # Create skill vectors\n",
    "    vector1 = np.array([1 if skill in list1 else 0 for skill in skills])\n",
    "    vector2 = np.array([1 if skill in list2 else 0 for skill in skills])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0  \n",
    "\n",
    "    return dot_product / (magnitude1 * magnitude2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f4cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('output/model-best')\n",
    "def extraire_competences(doc):\n",
    "    competences = [ent.text for ent in doc.ents if ent.label_ == 'SKILLS']  \n",
    "    return set(competences)\n",
    "\n",
    "\n",
    "def extraire_Noms(doc):\n",
    "    Noms = [ent.text for ent in doc.ents if ent.label_ == 'NAME']  \n",
    "    return set(Noms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22785adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_similarity(tx, nom1, nom2, similarity, skills1, skills2):\n",
    "    if similarity > 0.0:\n",
    "        similarity_label = f\"SIMILARITY_{round(similarity, 3)}\"\n",
    "        query = \"\"\"\n",
    "        MERGE (a:Consultant {name: $nom1})\n",
    "        SET a.skills = $skills1\n",
    "        MERGE (b:Consultant {name: $nom2})\n",
    "        SET b.skills = $skills2\n",
    "        MERGE (a)-[r:`\"\"\" + similarity_label + \"\"\"`]->(b)\n",
    "        SET r.score = $similarity\n",
    "        \"\"\"\n",
    "        tx.run(query, nom1=nom1, nom2=nom2, similarity=similarity, skills1=list(skills1), skills2=list(skills2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f6783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def comparer_tous_les_cv(dossier, uri, username, password):\n",
    "    fichiers = [f for f in os.listdir(dossier) if f.endswith('.docx')]\n",
    "    #driver \n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    \n",
    "    #with open(resultat_fichier, 'w', encoding='utf-8') as f_out:\n",
    "    with driver.session() as session:\n",
    "        for i in range(len(fichiers)):\n",
    "            for j in range(i + 1, len(fichiers)):\n",
    "                fichier1 = fichiers[i]\n",
    "                fichier2 = fichiers[j]\n",
    "                #load the file\n",
    "                chemin1 = os.path.join(dossier, fichier1)\n",
    "                chemin2 = os.path.join(dossier, fichier2)\n",
    "                #clean text\n",
    "                doc1=nlp(clean_text_from_file(chemin1))\n",
    "                doc2=nlp(clean_text_from_file(chemin2))\n",
    "                competences1 = extraire_competences(nlp(doc1))\n",
    "                competences2 = extraire_competences(nlp(doc2))\n",
    "                noms1 = list(extraire_Noms(nlp(doc1)))\n",
    "                noms2 = list(extraire_Noms(nlp(doc2)))\n",
    "                \n",
    "                if not noms1 or not noms2:\n",
    "                    continue\n",
    "                \n",
    "                NomConsultant1 = noms1[0]\n",
    "                NomConsultant2 = noms2[0]\n",
    "                #test de similarite\n",
    "                similarite = cosine_similarity(competences1, competences2)\n",
    "                \n",
    "                # Enregistrement du résultat dans le fichier de sortie\n",
    "                #ligne_resultat = f\"Similarité de Jaccard entre : '{NomConsultant1}' et '{NomConsultant2}' : {similarite:}\\n\"\n",
    "                #f_out.write(ligne_resultat)\n",
    "                \n",
    "                # Save the result in the Neo4j database\n",
    "                session.execute_write(\n",
    "                    save_similarity, NomConsultant1, NomConsultant2, similarite, competences1, competences2\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b164ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "\n",
    "\n",
    "dossier = 'Cv_DataSet'\n",
    "#resultat_fichier = 'res.txt'\n",
    "\n",
    "comparer_tous_les_cv(dossier, uri, username, password)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
